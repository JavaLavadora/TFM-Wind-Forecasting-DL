{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils.utils.config import Config\n",
    "from common_utils.io.data_access.data_access_factory import DataAccessFactory\n",
    "# from axpo_trading.forecast.forecast_preprocess_iberia import preproces_ufis\n",
    "from common_utils.utils import utils, utils_io, utils_date\n",
    "from axpo_trading.forecast import forecast_sql_preprocess_iberia\n",
    "from axpo_trading.forecast import forecast_preprocess_iberia\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "wind_path = \"/home/jovyan/projects/AdvancedAnalytics-UseCase-Wind\"\n",
    "os.chdir(wind_path)\n",
    "\n",
    "os.environ['CONFIG_DIR'] = 'config_files'\n",
    "os.environ['AUTH_CONFIG_DIR'] = 'auth'\n",
    "os.environ['AZURE_STORAGE_ACCOUNT_RAW_CONTAINER_NAME_WIND_RAW'] = 'raw'\n",
    "os.environ['AZURE_STORAGE_ACCOUNT_RAW_CONTAINER_NAME_WIND_STAGING'] = 'staging'\n",
    "os.environ[\"AZURE_SQL_SHARED_RAW_SERVER\"] = 'axso-prod-appl-aa-prod-shared-sql-secondary.database.windows.net'\n",
    "# os.environ[\"AZURE_SQL_SHARED_RAW_SERVER\"] = 'axso-prod-appl-aa-prod-shared-sql.database.windows.net'\n",
    "os.environ[\"AZURE_SQL_SHARED_RAW_DATABASE\"] = 'axso-prod-appl-aa-prod-shared-raw-sqldb'\n",
    "os.environ[\"N_THREADS_SQL\"] = \"1\"\n",
    "\n",
    "# DEV\n",
    "os.environ['ENV'] = 'azure_iberia_k8s_dev'\n",
    "# BLOB DEV\n",
    "os.environ['AZURE_STORAGE_ACCOUNT_DATA_NAME'] = 'axsonpaadevdslabdls'\n",
    "os.environ['AZURE_STORAGE_ACCOUNT_RAW_NAME'] = 'axsoprodaaprodshareddls-secondary'\n",
    "os.environ['AZURE_STORAGE_ACCOUNT_DATA_CONTAINER_NAME_WIND_REFINED'] = 'wind-refined'\n",
    "os.environ['AZURE_STORAGE_ACCOUNT_DATA_CONTAINER_NAME_WIND_RESULTS'] = 'wind-results'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get Eolic UFIS for the given dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_from = \"2020-08-01\"\n",
    "date_from = \"2019-01-01\"\n",
    "date_to = \"2022-10-30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-25 19:13:07,451 - MainThread - [INFO] - b'[AD AUTH] - get_token at line 150: Token for resource axso-prod-appl-aa-prod-shared-raw-sqldb. Valid until 2023-01-26T18:13:06'\n"
     ]
    }
   ],
   "source": [
    "eolic_ufis_query = \"SELECT CDUNIFIS, CDUNIPROG, NUMREGISTRO, FEALTA, FEBAJA, provincia, ubicacion, Latitud as lat, Longitud as lon, PTMAXIMA, PTMINIMA, TIPOUNIFIS, COMISIONMWH, codCliente, cliente, \\\n",
    "\t \t\t\t\t\t\tCOEFREPARTO, COEFPERDIDAS, INDCOSTEDES, DISTRIBUIDORA, FACTURAR_MI, CONSG_REACTIVA, FEULTMOD \\\n",
    "\t\t\t\t\tFROM [HISTORIAN].[DatosInstalaciones] A \\\n",
    "\t\t\t\t\tINNER JOIN (\\\n",
    "\t\t\t\t\t\tSELECT * FROM [EGL].[SYS_UNIDAD_FISICA] WHERE TIPOUNIFIS='EO' \\\n",
    "\t\t\t\t\t) B \\\n",
    "\t\t\t\t\tON A.codUFisica = B.CDUNIFIS\"\n",
    "\n",
    "config_dict = Config.get_config()\n",
    "data_config = config_dict[\"data_access_factory\"]\n",
    "factory = DataAccessFactory()\n",
    "\n",
    "source = factory.get(data_config[\"pre_master_forecast\"][\"source\"])\n",
    "eo_ufis = source.get(eolic_ufis_query)\n",
    "\n",
    "# Can't use the existing one since it skips lat lon data :(\n",
    "def preproces_ufis(\n",
    "    date_to, ufi_up, date_from=None, add_limit=False, add_datetime_col=False, usecase=None, valid_units=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess ufis table into standardized (std_ufi) table\n",
    "\n",
    "    :param date_to: end date (type: str)\n",
    "    :param ufi_up: raw ufi table (type: pd.DataFrame)\n",
    "    :param date_from: start date (type: str)\n",
    "    :param add_limit: flag to add extra capacity limitations. Expands the table to hourly resolution (type: boolean)\n",
    "    :param add_datetime_col: flag to add the column datetime (type: boolean)\n",
    "    :param usecase: usecase to use to add extra capacity limitations (type: str)\n",
    "    :return: processed table (type: pd.DataFrame)\n",
    "    \"\"\"\n",
    "\n",
    "    if valid_units is not None:\n",
    "        ufi_up = ufi_up[ufi_up[\"CDUNIFIS\"].isin(valid_units)]\n",
    "\n",
    "    # Converting columns to datetime\n",
    "    # logger.info(\"Casting columns to date format\")\n",
    "    ufi_up[\"FEALTA\"] = pd.to_datetime(ufi_up[\"FEALTA\"], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    ufi_up[\"FEBAJA\"] = pd.to_datetime(ufi_up[\"FEBAJA\"], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "    # Filling NA to_dates, and cliping dates over today, to today\n",
    "    date_to_plus_one = pd.to_datetime(date_to) + pd.Timedelta(1, unit=\"D\")\n",
    "    ufi_up = ufi_up[ufi_up[\"FEALTA\"] <= date_to_plus_one].copy()\n",
    "    ufi_up.loc[ufi_up[\"FEBAJA\"].isnull(), \"FEBAJA\"] = date_to_plus_one\n",
    "    ufi_up.loc[ufi_up[\"FEBAJA\"] > date_to_plus_one, \"FEBAJA\"] = date_to_plus_one\n",
    "    # logger.info(\"Expanding UFI table\")\n",
    "\n",
    "    # Expand dates\n",
    "    cols_use = [\n",
    "        \"TIPOUNIFIS\",\n",
    "        \"COMISIONMWH\",\n",
    "        \"COEFREPARTO\",\n",
    "        \"COEFPERDIDAS\",\n",
    "        \"INDCOSTEDES\",\n",
    "        \"DISTRIBUIDORA\",\n",
    "        \"FACTURAR_MI\",\n",
    "        \"CONSG_REACTIVA\",\n",
    "        \"provincia\",\n",
    "        \"ubicacion\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "        \"codCliente\"\n",
    "    ]\n",
    "\n",
    "    # ufi_up_expanded = utils.expand_dates(ufi_up,\n",
    "    ufi = utils_date.expand_dates(\n",
    "        ufi_up,\n",
    "        key_cols=[\"CDUNIFIS\", \"CDUNIPROG\", \"PTMAXIMA\", \"PTMINIMA\"] + cols_use,\n",
    "        from_col=\"FEALTA\",\n",
    "        to_col=\"FEBAJA\",\n",
    "        include_last=False,\n",
    "    )\n",
    "\n",
    "    # Consolidating into ufi-uo table renaming and filtering\n",
    "    ufi.rename(\n",
    "        columns={\"CDUNIFIS\": \"ufi\", \"CDUNIPROG\": \"up\", \"PTMAXIMA\": \"p_max\", \"PTMINIMA\": \"p_min\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "    ufi = ufi[[\"ufi\", \"up\", \"date\", \"p_max\", \"p_min\"] + cols_use]\n",
    "    ufi[\"date\"] = pd.to_datetime(ufi[\"date\"], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    ufi.drop_duplicates(subset=[\"ufi\", \"date\"], keep=\"last\", inplace=True)\n",
    "    if date_from is not None:\n",
    "        ufi = ufi[ufi[\"date\"] >= pd.to_datetime(date_from)]\n",
    "    # # Add extra capacity limitations\n",
    "    # if add_limit:\n",
    "    #     ufi = add_ufi_limit(ufi)\n",
    "\n",
    "    # Transform to QH\n",
    "    # if add_datetime_col:\n",
    "    #     ufi = utils_date.add_datetime_columns(ufi, hour_band_right=True)\n",
    "\n",
    "    return ufi\n",
    "\n",
    "ufi = preproces_ufis(date_to, eo_ufis, date_from, valid_units=eo_ufis[\"CDUNIFIS\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufi.to_csv(\"data/tfm/ufi.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get the meterings for the given dates (target for the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-25 19:13:16,578 - MainThread - [INFO] - b'[FORECAST SQL PREPROCESS IBERIA] - process_sql_meterings_stand_alone at line 429: date_from: 2019-01-01'\n",
      "2023-01-25 19:13:16,597 - MainThread - [INFO] - b'[FORECAST SQL PREPROCESS IBERIA] - process_sql_meterings_stand_alone at line 430: date_to: 2022-10-30'\n",
      "2023-01-25 19:13:17,054 - MainThread - [INFO] - b'[FORECAST SQL PREPROCESS IBERIA] - pull_metering_from_sql at line 529: Establishing connection to database'\n",
      "2023-01-25 19:13:17,074 - MainThread - [INFO] - b'[FORECAST SQL PREPROCESS IBERIA] - pull_metering_from_sql at line 538: Downloading tables'\n",
      "2023-01-25 19:15:02,452 - MainThread - [INFO] - b'[FORECAST PREPROCESS IBERIA] - preprocess_metering at line 898: Pre-processing meterings'\n"
     ]
    }
   ],
   "source": [
    "# Meterings (target)\n",
    "meterings = forecast_sql_preprocess_iberia.process_sql_meterings_stand_alone(\n",
    "    date_from=date_from,\n",
    "    date_to=date_to,\n",
    "    real_time=False,\n",
    ")\n",
    "\n",
    "meterings = forecast_preprocess_iberia.preprocess_metering(date_from, date_to, meterings, ufi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meterings.to_csv(\"data/tfm/meterings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Get the telemetry for the given dates. It will help the model to correct forecast predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-25 19:15:14,524 - MainThread - [INFO] - b'[FORECAST SQL PREPROCESS IBERIA] - pull_telemetry_from_sql at line 673: [SQL TELEMETRY] Establishing connection to database'\n",
      "2023-01-25 19:15:15,051 - MainThread - [INFO] - b'[FORECAST SQL PREPROCESS IBERIA] - get_telemetry_for_tags at line 747: Downloading telemetry data from Historian database for        93 UFIs between 2019-01-01 and 2022-10-30...'\n",
      "2023-01-25 19:15:15,076 - MainThread - [INFO] - b'[FORECAST SQL PREPROCESS IBERIA] - get_telemetry_for_tags at line 774: [SQL TELEMETRY] RUNNING QUERY'\n"
     ]
    }
   ],
   "source": [
    "telemetry = forecast_sql_preprocess_iberia.pull_telemetry_from_sql(ufi[\"ufi\"].unique(), date_from, date_to)\n",
    "telemetry = forecast_preprocess_iberia.preprocess_telemetry(telemetry, ufi, portfolio_level=False, upsample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AMPLESC', 'ARTEIXO', 'ATALAYA', 'BAYO', 'AZUBIAS', 'BANDELE',\n",
       "       'CHANTAD', 'AEROGEN', 'CPELAOS', 'PEARBO', 'BRULLES', 'ASNEVES',\n",
       "       'PEOCHAO', 'COFRENT', 'PECOUTE', 'FEIXOS', 'PECUEVA', 'DEHESII',\n",
       "       'DEHEII', 'OTERO', 'ELLLAN', 'ESCANDO', 'ESQUILE', 'FARELO',\n",
       "       'CERCEDA', 'ELGALLO', 'GECAMA', 'HINOJAI', 'HINOJII', 'CALERA',\n",
       "       'GRAIADE', 'PEIRIXO', 'CAMPANA', 'ESE', 'LACAYA', 'FRAILA',\n",
       "       'HERRERI', 'PELALOM', 'LALOMBA', 'LAMESA', 'LARUYA', 'LASORDA',\n",
       "       'TRAPERA', 'COMES', 'CERROS', 'MALPICA', 'MONDONE', 'POTRA',\n",
       "       'ABELLA', 'MCABEZA', 'MONTERO', 'MONTCEO', 'CIERZO1', 'CIERZO2',\n",
       "       'MONTOUT', 'MUDEFER', 'DEFERII', 'CADEIR', 'CARRACE', 'NEDAPE',\n",
       "       'PEAPAS', 'SASDOI', 'SASDON', 'PEOUROL', 'SPADRON', 'PTEJADA',\n",
       "       'PEDREGA', 'PEDREGB', 'PEDREGD', 'PGRANDE', 'PECORTI', 'PPOZA1',\n",
       "       'PICADOR', 'PPOZA2', 'RODERA', 'ROMERA', 'SABUCED', 'SANJOSE',\n",
       "       'PESLOA', 'PESLOB', 'PESLOC', 'PESLOD', 'SERRETA', 'TIGUEIR',\n",
       "       'VILACHA', 'VISOS', 'AXIABRE', 'ZAPATER', 'PEZARZU', 'ZARZUEL'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telemetry[\"ufi\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry.to_csv(\"data/tfm/telemetry.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Get Forecasts to improve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-25 19:17:38,910 - MainThread - [INFO] - b'[UTILS IO] - load_monthly at line 176: Loading monthly from : forecast/research/raw_forecasts_eolic'\n",
      "2023-01-25 19:17:38,929 - MainThread - [INFO] - b'[UTILS IO] - format_dates at line 465: 2019-01-01'\n",
      "2023-01-25 19:17:38,994 - MainThread - [INFO] - b\"[UTILS IO] - filter_files_load_monthly at line 448: Files in path: ['raw_forecasts_eolic___202206_0.h5', 'raw_forecasts_eolic___202208_0.h5', 'raw_forecasts_eolic___201912_0.h5', 'raw_forecasts_eolic___201911_0.h5', 'raw_forecasts_eolic___201903_0.h5', 'raw_forecasts_eolic___201909_0.h5', 'raw_forecasts_eolic___202204_0.h5', 'raw_forecasts_eolic___202210_0.h5', 'raw_forecasts_eolic___202011_0.h5', 'raw_forecasts_eolic___202008_0.h5', 'raw_forecasts_eolic___202111_0.h5', 'raw_forecasts_eolic___202003_0.h5', 'raw_forecasts_eolic___202202_0.h5', 'raw_forecasts_eolic___201901_0.h5', 'raw_forecasts_eolic___202107_0.h5', 'raw_forecasts_eolic___202001_0.h5', 'raw_forecasts_eolic___201907_0.h5', 'raw_forecasts_eolic___202005_0.h5', 'raw_forecasts_eolic___202101_0.h5', 'raw_forecasts_eolic___202201_0.h5', 'raw_forecasts_eolic___202205_0.h5', 'raw_forecasts_eolic___201902_0.h5', 'raw_forecasts_eolic___202007_0.h5', 'raw_forecasts_eolic___201910_0.h5', 'raw_forecasts_eolic___202105_0.h5', 'raw_forecasts_eolic___202012_0.h5', 'raw_forecasts_eolic___202009_0.h5', 'raw_forecasts_eolic___202110_0.h5', 'raw_forecasts_eolic___202102_0.h5', 'raw_forecasts_eolic___201908_0.h5', 'raw_forecasts_eolic___201904_0.h5', 'raw_forecasts_eolic___202004_0.h5', 'raw_forecasts_eolic___202112_0.h5', 'raw_forecasts_eolic___201906_0.h5', 'raw_forecasts_eolic___202203_0.h5', 'raw_forecasts_eolic___202104_0.h5', 'raw_forecasts_eolic___202010_0.h5', 'raw_forecasts_eolic___202207_0.h5', 'raw_forecasts_eolic___202108_0.h5', 'raw_forecasts_eolic___202002_0.h5', 'raw_forecasts_eolic___201905_0.h5', 'raw_forecasts_eolic___202209_0.h5', 'raw_forecasts_eolic___202106_0.h5', 'raw_forecasts_eolic___202006_0.h5', 'raw_forecasts_eolic___202109_0.h5', 'raw_forecasts_eolic___202103_0.h5']\"\n",
      "2023-01-25 19:17:39,018 - MainThread - [INFO] - b\"[UTILS IO] - filter_files_load_monthly at line 451: dates: [Timestamp('2022-06-01 00:00:00'), Timestamp('2022-08-01 00:00:00'), Timestamp('2019-12-01 00:00:00'), Timestamp('2019-11-01 00:00:00'), Timestamp('2019-03-01 00:00:00'), Timestamp('2019-09-01 00:00:00'), Timestamp('2022-04-01 00:00:00'), Timestamp('2022-10-01 00:00:00'), Timestamp('2020-11-01 00:00:00'), Timestamp('2020-08-01 00:00:00'), Timestamp('2021-11-01 00:00:00'), Timestamp('2020-03-01 00:00:00'), Timestamp('2022-02-01 00:00:00'), Timestamp('2019-01-01 00:00:00'), Timestamp('2021-07-01 00:00:00'), Timestamp('2020-01-01 00:00:00'), Timestamp('2019-07-01 00:00:00'), Timestamp('2020-05-01 00:00:00'), Timestamp('2021-01-01 00:00:00'), Timestamp('2022-01-01 00:00:00'), Timestamp('2022-05-01 00:00:00'), Timestamp('2019-02-01 00:00:00'), Timestamp('2020-07-01 00:00:00'), Timestamp('2019-10-01 00:00:00'), Timestamp('2021-05-01 00:00:00'), Timestamp('2020-12-01 00:00:00'), Timestamp('2020-09-01 00:00:00'), Timestamp('2021-10-01 00:00:00'), Timestamp('2021-02-01 00:00:00'), Timestamp('2019-08-01 00:00:00'), Timestamp('2019-04-01 00:00:00'), Timestamp('2020-04-01 00:00:00'), Timestamp('2021-12-01 00:00:00'), Timestamp('2019-06-01 00:00:00'), Timestamp('2022-03-01 00:00:00'), Timestamp('2021-04-01 00:00:00'), Timestamp('2020-10-01 00:00:00'), Timestamp('2022-07-01 00:00:00'), Timestamp('2021-08-01 00:00:00'), Timestamp('2020-02-01 00:00:00'), Timestamp('2019-05-01 00:00:00'), Timestamp('2022-09-01 00:00:00'), Timestamp('2021-06-01 00:00:00'), Timestamp('2020-06-01 00:00:00'), Timestamp('2021-09-01 00:00:00'), Timestamp('2021-03-01 00:00:00')]\"\n",
      "2023-01-25 19:17:39,036 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___201901_0.h5'\n",
      "2023-01-25 19:17:40,431 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___201902_0.h5'\n",
      "2023-01-25 19:17:41,576 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___201903_0.h5'\n",
      "2023-01-25 19:17:42,788 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___201904_0.h5'\n",
      "2023-01-25 19:17:44,039 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___201905_0.h5'\n",
      "2023-01-25 19:17:45,196 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___201906_0.h5'\n",
      "2023-01-25 19:17:46,340 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___201907_0.h5'\n",
      "2023-01-25 19:17:47,580 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___201908_0.h5'\n",
      "2023-01-25 19:17:49,100 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___201909_0.h5'\n",
      "2023-01-25 19:17:50,332 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___201910_0.h5'\n",
      "2023-01-25 19:17:51,916 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___201911_0.h5'\n",
      "2023-01-25 19:17:53,175 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___201912_0.h5'\n",
      "2023-01-25 19:17:54,572 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202001_0.h5'\n",
      "2023-01-25 19:17:56,083 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202002_0.h5'\n",
      "2023-01-25 19:17:57,372 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202003_0.h5'\n",
      "2023-01-25 19:17:58,812 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202004_0.h5'\n",
      "2023-01-25 19:18:00,291 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202005_0.h5'\n",
      "2023-01-25 19:18:01,883 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202006_0.h5'\n",
      "2023-01-25 19:18:03,320 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202007_0.h5'\n",
      "2023-01-25 19:18:04,732 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202008_0.h5'\n",
      "2023-01-25 19:18:06,265 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202009_0.h5'\n",
      "2023-01-25 19:18:07,640 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202010_0.h5'\n",
      "2023-01-25 19:18:08,991 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202011_0.h5'\n",
      "2023-01-25 19:18:10,337 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202012_0.h5'\n",
      "2023-01-25 19:18:11,680 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202101_0.h5'\n",
      "2023-01-25 19:18:12,937 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202102_0.h5'\n",
      "2023-01-25 19:18:14,010 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202103_0.h5'\n",
      "2023-01-25 19:18:15,184 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202104_0.h5'\n",
      "2023-01-25 19:18:16,308 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202105_0.h5'\n",
      "2023-01-25 19:18:17,501 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202106_0.h5'\n",
      "2023-01-25 19:18:18,581 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202107_0.h5'\n",
      "2023-01-25 19:18:19,764 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202108_0.h5'\n",
      "2023-01-25 19:18:20,887 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202109_0.h5'\n",
      "2023-01-25 19:18:21,959 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202110_0.h5'\n",
      "2023-01-25 19:18:23,101 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202111_0.h5'\n",
      "2023-01-25 19:18:24,311 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202112_0.h5'\n",
      "2023-01-25 19:18:25,469 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202201_0.h5'\n",
      "2023-01-25 19:18:26,962 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202202_0.h5'\n",
      "2023-01-25 19:18:27,907 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202203_0.h5'\n",
      "2023-01-25 19:18:29,025 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202204_0.h5'\n",
      "2023-01-25 19:18:30,157 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202205_0.h5'\n",
      "2023-01-25 19:18:31,286 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202206_0.h5'\n",
      "2023-01-25 19:18:32,359 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202207_0.h5'\n",
      "2023-01-25 19:18:33,488 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202208_0.h5'\n",
      "2023-01-25 19:18:34,775 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202209_0.h5'\n",
      "2023-01-25 19:18:35,843 - MainThread - [INFO] - b'[UTILS IO] - get_files_without_sampling at line 398: Reading file raw_forecasts_eolic___202210_0.h5'\n",
      "2023-01-25 19:19:07,858 - MainThread - [INFO] - b'[FORECAST PREPROCESS IBERIA] - preprocess_std_forecast at line 843: Filtering UFIs in forecast'\n",
      "2023-01-25 19:19:07,879 - MainThread - [INFO] - b'[FORECAST PREPROCESS IBERIA] - preprocess_std_forecast at line 858: Filtering intersection between forecast and portfolio'\n"
     ]
    }
   ],
   "source": [
    "data_config = Config.get_config()[\"data_access_factory\"]\n",
    "factory = DataAccessFactory()\n",
    "\n",
    "sink = factory.get(data_config[\"master_overcost\"][\"source\"])\n",
    "\n",
    "path = \"forecast/research/raw_forecasts_eolic\"\n",
    "# date_from_fcst = \"2020-07-31\"\n",
    "# date_to_fcst = \"2022-02-01\"\n",
    "\n",
    "markets_to_run = [\"MD\",\"MI1\",\"MI2\",\"MI3\",\"MI4\",\"MI5\",\"MI6\",\"MI7\",\"mic_1\",\"mic_2\",\"mic_3\",\"mic_4\",\"mic_5\",\"mic_6\",\"mic_7\",\"mic_8\",\"mic_9\",\"mic_10\",\"mic_11\",\"mic_12\",\"mic_13\",\"mic_14\",\"mic_15\",\"mic_16\",\"mic_17\",\"mic_18\",\"mic_19\",\"mic_20\",\"mic_21\",\"mic_22\",\"mic_23\",\"mic_24\",\"tertiary_1\",\"tertiary_2\",\"tertiary_3\",\"tertiary_4\",\"tertiary_5\",\"tertiary_6\",\"tertiary_7\",\"tertiary_8\",\"tertiary_9\",\"tertiary_10\",\"tertiary_11\",\"tertiary_12\",\"tertiary_13\",\"tertiary_14\",\"tertiary_15\",\"tertiary_16\",\"tertiary_17\",\"tertiary_18\",\"tertiary_19\",\"tertiary_20\",\"tertiary_21\",\"tertiary_22\",\"tertiary_23\",\"tertiary_24\"]\n",
    "\n",
    "# This takes too long so I did it on the cluster (run/iberia/fcst-on-cluster)\n",
    "# forecasts = forecast_sql_preprocess_iberia.preprocess_sql_forecast(\n",
    "#     date_from, date_to, markets_to_run, stand_alone=True, append_to_master=False, valid_ufis=ufi[\"ufi\"].unique()\n",
    "# )\n",
    "# Instead we read the results from blob (generated in run/iberia/fcst-on-cluster)\n",
    "forecasts = utils_io.load_monthly(\n",
    "    path=path,\n",
    "    date_col=\"date\",\n",
    "    date_from=date_from,\n",
    "    date_to=date_to,\n",
    "    data_access=sink,\n",
    ")\n",
    "\n",
    "forecasts = forecast_preprocess_iberia.preprocess_std_forecast(forecasts, False, ufi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts.to_csv(\"data/tfm/forecasts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create premaster table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-25 19:25:06,444 - MainThread - [INFO] - b'[FORECAST PREPROCESS IBERIA] - drop_duplicates at line 1469: Making sure there are no duplicates in std tables'\n",
      "Appending metering to master\n",
      "Appending UFI information\n"
     ]
    }
   ],
   "source": [
    "unit_col_name = \"ufi\"\n",
    "datetime_cols =  [\"datetime\",\"date\",\"hour\",\"minute\"]\n",
    "col_zone= \"zone\"\n",
    "\n",
    "# Dates\n",
    "forecasts, meterings, ufi = forecast_preprocess_iberia.cast_dates_before_master(forecasts, meterings, ufi)\n",
    "forecasts, meterings, ufi = forecast_preprocess_iberia.filter_dates(date_from, date_to, forecasts, meterings, ufi)\n",
    "\n",
    "# Prepare data for master\n",
    "forecast_preprocess_iberia.drop_duplicates(forecasts, meterings, ufi)\n",
    "forecasts = forecast_preprocess_iberia.prepare_forecast_for_master(forecasts)\n",
    "\n",
    "print(\"Appending metering to master\")\n",
    "master = forecasts.merge(meterings, on=datetime_cols + [\"ufi\"], how=\"left\")\n",
    "master[\"zone\"] = \"iberia\"\n",
    "print(\"Appending UFI information\")\n",
    "master = master.merge(ufi, on=[\"ufi\", \"date\"], how=\"left\")\n",
    "\n",
    "# Prepare data for master\n",
    "telemetry[\"date\"] = pd.to_datetime(telemetry[\"date\"]).dt.date\n",
    "telemetry = telemetry[\n",
    "    (telemetry[\"date\"] >= pd.to_datetime(date_from).date() - pd.Timedelta(1, unit=\"d\"))\n",
    "    & (telemetry[\"date\"] <= pd.to_datetime(date_to).date())\n",
    "]\n",
    "telemetry.drop_duplicates(subset=[\"datetime\", \"date\", \"hour\", \"ufi\"], inplace=True)\n",
    "telemetry = telemetry.reset_index(drop=True)\n",
    "# Add telemetry data available at market time: Telemetry is inserted with 1h delay\n",
    "telemetry[\"datetime_telem_available_delete\"] = telemetry[\"datetime\"] + pd.Timedelta(\"1h\")\n",
    "\n",
    "master = master.merge(\n",
    "    telemetry,\n",
    "    left_on=[\"datetime_market\"] + [unit_col_name],\n",
    "    right_on=[\"datetime_telem_available_delete\"] + [unit_col_name],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_delete\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_market</th>\n",
       "      <th>datetime</th>\n",
       "      <th>ufi</th>\n",
       "      <th>telemetry</th>\n",
       "      <th>forecast</th>\n",
       "      <th>metering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 11:00:00</td>\n",
       "      <td>2019-01-02 00:00:00</td>\n",
       "      <td>TRAPERA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 11:00:00</td>\n",
       "      <td>2019-01-02 01:00:00</td>\n",
       "      <td>TRAPERA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 11:00:00</td>\n",
       "      <td>2019-01-02 02:00:00</td>\n",
       "      <td>TRAPERA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 11:00:00</td>\n",
       "      <td>2019-01-02 03:00:00</td>\n",
       "      <td>TRAPERA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 11:00:00</td>\n",
       "      <td>2019-01-02 04:00:00</td>\n",
       "      <td>TRAPERA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26815780</th>\n",
       "      <td>2022-10-30 19:00:00</td>\n",
       "      <td>2022-10-30 20:00:00</td>\n",
       "      <td>PELALIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26815781</th>\n",
       "      <td>2022-10-30 20:00:00</td>\n",
       "      <td>2022-10-30 21:00:00</td>\n",
       "      <td>PELALIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26815782</th>\n",
       "      <td>2022-10-30 21:00:00</td>\n",
       "      <td>2022-10-30 22:00:00</td>\n",
       "      <td>PELALIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26815783</th>\n",
       "      <td>2022-10-30 22:00:00</td>\n",
       "      <td>2022-10-30 23:00:00</td>\n",
       "      <td>PELALIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26815784</th>\n",
       "      <td>2022-10-29 23:00:00</td>\n",
       "      <td>2022-10-30 00:00:00</td>\n",
       "      <td>PELALIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26815785 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime_market            datetime      ufi  telemetry  \\\n",
       "0        2019-01-01 11:00:00 2019-01-02 00:00:00  TRAPERA        NaN   \n",
       "1        2019-01-01 11:00:00 2019-01-02 01:00:00  TRAPERA        NaN   \n",
       "2        2019-01-01 11:00:00 2019-01-02 02:00:00  TRAPERA        NaN   \n",
       "3        2019-01-01 11:00:00 2019-01-02 03:00:00  TRAPERA        NaN   \n",
       "4        2019-01-01 11:00:00 2019-01-02 04:00:00  TRAPERA        NaN   \n",
       "...                      ...                 ...      ...        ...   \n",
       "26815780 2022-10-30 19:00:00 2022-10-30 20:00:00  PELALIN        NaN   \n",
       "26815781 2022-10-30 20:00:00 2022-10-30 21:00:00  PELALIN        NaN   \n",
       "26815782 2022-10-30 21:00:00 2022-10-30 22:00:00  PELALIN        NaN   \n",
       "26815783 2022-10-30 22:00:00 2022-10-30 23:00:00  PELALIN        NaN   \n",
       "26815784 2022-10-29 23:00:00 2022-10-30 00:00:00  PELALIN        NaN   \n",
       "\n",
       "          forecast  metering  \n",
       "0              0.0     0.000  \n",
       "1              0.0     0.000  \n",
       "2              0.0     0.000  \n",
       "3              0.0     0.000  \n",
       "4              0.1     0.000  \n",
       "...            ...       ...  \n",
       "26815780       0.4     0.871  \n",
       "26815781       0.8     1.261  \n",
       "26815782       1.3     1.866  \n",
       "26815783       1.7     2.252  \n",
       "26815784       1.5     1.631  \n",
       "\n",
       "[26815785 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master[[\"datetime_market\",\"datetime\",\"ufi\",\"telemetry\",\"forecast\",\"metering\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.to_csv(\"data/tfm/premaster_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-25 19:28:44,499 - MainThread - [INFO] - b'[UTILS IO] - save_monthly at line 87: Saving table in forecast/research/premaster_eolic'\n",
      "2023-01-25 19:28:49,531 - MainThread - [INFO] - b'[MULTITHREADING] - apply_multithread at line 55: Using 1 threads'\n",
      "2023-01-25 19:28:49,552 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 201901'\n",
      "2023-01-25 19:28:58,757 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 201902'\n",
      "2023-01-25 19:29:04,264 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 201903'\n",
      "2023-01-25 19:29:10,272 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 201904'\n",
      "2023-01-25 19:29:15,763 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 201905'\n",
      "2023-01-25 19:29:21,436 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 201906'\n",
      "2023-01-25 19:29:27,117 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 201907'\n",
      "2023-01-25 19:29:32,961 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 201908'\n",
      "2023-01-25 19:29:38,858 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 201909'\n",
      "2023-01-25 19:29:44,289 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 201910'\n",
      "2023-01-25 19:29:50,255 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 201911'\n",
      "2023-01-25 19:29:56,081 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 201912'\n",
      "2023-01-25 19:30:02,466 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202001'\n",
      "2023-01-25 19:30:08,916 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202002'\n",
      "2023-01-25 19:30:14,918 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202003'\n",
      "2023-01-25 19:30:21,298 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202004'\n",
      "2023-01-25 19:30:27,949 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202005'\n",
      "2023-01-25 19:30:34,427 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202006'\n",
      "2023-01-25 19:30:40,589 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202007'\n",
      "2023-01-25 19:30:46,779 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202008'\n",
      "2023-01-25 19:30:53,108 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202009'\n",
      "2023-01-25 19:30:59,264 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202010'\n",
      "2023-01-25 19:31:05,649 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202011'\n",
      "2023-01-25 19:31:11,635 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202012'\n",
      "2023-01-25 19:31:17,859 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202101'\n",
      "2023-01-25 19:31:23,208 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202102'\n",
      "2023-01-25 19:31:28,028 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202103'\n",
      "2023-01-25 19:31:33,371 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202104'\n",
      "2023-01-25 19:31:38,542 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202105'\n",
      "2023-01-25 19:31:43,877 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202106'\n",
      "2023-01-25 19:31:48,846 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202107'\n",
      "2023-01-25 19:31:54,092 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202108'\n",
      "2023-01-25 19:31:59,394 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202109'\n",
      "2023-01-25 19:32:04,408 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202110'\n",
      "2023-01-25 19:32:09,835 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202111'\n",
      "2023-01-25 19:32:14,858 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202112'\n",
      "2023-01-25 19:32:20,014 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202201'\n",
      "2023-01-25 19:32:25,237 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202202'\n",
      "2023-01-25 19:32:29,848 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202203'\n",
      "2023-01-25 19:32:35,220 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202204'\n",
      "2023-01-25 19:32:40,209 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202205'\n",
      "2023-01-25 19:32:45,370 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202206'\n",
      "2023-01-25 19:32:50,411 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202207'\n",
      "2023-01-25 19:32:55,469 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202208'\n",
      "2023-01-25 19:33:00,523 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202209'\n",
      "2023-01-25 19:33:05,513 - MainThread - [INFO] - b'[UTILS IO] - save_month at line 124: Saving date 202210'\n"
     ]
    }
   ],
   "source": [
    "utils_io.save_monthly(\n",
    "    table=master,\n",
    "    path=\"forecast/research/premaster_eolic\",\n",
    "    date_col=\"datetime\",\n",
    "    table_name=\"premaster_eolic\",\n",
    "    file_format=\"hdf\",\n",
    "    data_access=sink,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:windTFM]",
   "language": "python",
   "name": "conda-env-windTFM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "10a9acedd02d255866dc9e77f348a56266dd6564e7333c21d8f589ea649c6a46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
